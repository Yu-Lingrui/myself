{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7af62ffa",
   "metadata": {},
   "source": [
    "# 小结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cda899f",
   "metadata": {},
   "source": [
    "• 标量、向量、矩阵和张量是线性代数中的基本数学对象。    \n",
    "• 向量泛化⾃标量，矩阵泛化⾃向量。    \n",
    "• 标量、向量、矩阵和张量分别具有零、⼀、⼆和任意数量的轴。      \n",
    "• ⼀个张量可以通过sum和mean沿指定的轴降低维度。    \n",
    "• 两个矩阵的按元素乘法被称为他们的Hadamard积(点积)。它与矩阵乘法不同。   \n",
    "• 在深度学习中，我们经常使⽤范数，如L1范数、L2范数和Frobenius范数。    \n",
    "• 我们可以对标量、向量、矩阵和张量执⾏各种操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21ba367",
   "metadata": {},
   "source": [
    "# 练习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee00365d",
   "metadata": {},
   "source": [
    "1. 证明⼀个矩阵A的转置的转置是A，即(A⊤)⊤ = A。\n",
    "2. 给出两个矩阵A和B，证明“它们转置的和”等于“它们和的转置”，即A⊤ + B⊤ = (A + B)⊤。\n",
    "3. 给定任意⽅阵A，A + A⊤总是对称的吗?为什么?\n",
    "4. 我们在本节中定义了形状(2, 3, 4)的张量X。len(X)的输出结果是什么？\n",
    "5. 对于任意形状的张量X,len(X)是否总是对应于X特定轴的⻓度?这个轴是什么?\n",
    "6. 运⾏A/A.sum(axis=1)，看看会发⽣什么。你能分析原因吗？\n",
    "7. 考虑⼀个具有形状(2, 3, 4)的张量，在轴0、1、2上的求和输出是什么形状?\n",
    "8. 为linalg.norm函数提供3个或更多轴的张量，并观察其输出。对于任意形状的张量这个函数计算得到什么?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8670d6",
   "metadata": {},
   "source": [
    "1.\n",
    "对于A中的一个元素aij，其在第 i 行第 j 列，转置后出现在第 j 行第 i 列，再转置一次就出现在第 i 行第 j 列，又回到了原来的位置。所以，一个矩阵转置的转置还是它自己。\n",
    "\n",
    "2.\n",
    "假设 A 第 i 行第 j 列的元素是 aij，B 第 i 行第 j 列的元素是 bij，两者均在。对于 AT + BT，其第 j 行第 i 列的值为 aij + bij；对于 (A + B)T，其第 j 行第 i 列的值也为 aij + bij，推广至即可知 AT + BT = (A + B)T。\n",
    "\n",
    "3.\n",
    "是，因为 (A + AT)T = AT + (AT)T = A + AT。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdca2c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4,5\n",
    "import torch\n",
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "len(X)\n",
    "#总输出0轴维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a112a935",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_52668/3808443475.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "#6\n",
    "A/A.sum(axis=1)\n",
    "#发生运行时错误，原因是 A 是一个 5 * 4 的矩阵，而 A.sum(axis=1) 是一个大小为 5 的向量，两者不能相除。   \n",
    "#（注：广播机制只能发生在两者维数相同的情况下）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "663149e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 6.],\n",
       "         [22.],\n",
       "         [38.],\n",
       "         [54.],\n",
       "         [70.]]),\n",
       " tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
       "         [0.1818, 0.2273, 0.2727, 0.3182],\n",
       "         [0.2105, 0.2368, 0.2632, 0.2895],\n",
       "         [0.2222, 0.2407, 0.2593, 0.2778],\n",
       "         [0.2286, 0.2429, 0.2571, 0.2714]]),\n",
       " tensor([ 6., 22., 38., 54., 70.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6修改\n",
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "sum_A = A.sum(axis=1, keepdims=True)#指定轴降维变成1->（5,1）,默认False则是直接去掉\n",
    "A,sum_A,A/sum_A,A.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c56e0495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11]],\n",
       " \n",
       "         [[12, 13, 14, 15],\n",
       "          [16, 17, 18, 19],\n",
       "          [20, 21, 22, 23]]]),\n",
       " tensor([[12, 14, 16, 18],\n",
       "         [20, 22, 24, 26],\n",
       "         [28, 30, 32, 34]]),\n",
       " tensor([[12, 15, 18, 21],\n",
       "         [48, 51, 54, 57]]),\n",
       " tensor([[ 6, 22, 38],\n",
       "         [54, 70, 86]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7\n",
    "X,X.sum(axis=0),X.sum(axis=1),X.sum(axis=2)\n",
    "#在轴 0 上求和，形状为 [3 * 4]\n",
    "#在轴 1 上求和，形状为 [2 * 4]\n",
    "#在轴 2 上求和，形状为 [2 * 3]\n",
    "#相当于对哪个轴求和，就是降维去掉哪个轴。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e5adb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.0, tensor(10.))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8\n",
    "#计算得到张量中所有值的 L2范数-Frobenius范数（Frobenius norm）是矩阵元素平⽅和的平⽅根\n",
    "#linalg.norm 其实是 numpy 的一个模块，功能是求各种范式，默认为L2范数=torch.norm\n",
    "import numpy as np\n",
    "Y=np.ones((2,5,10))\n",
    "np.linalg.norm(Y),torch.norm(torch.ones((2,5,10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
