{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ba7b66a",
   "metadata": {},
   "source": [
    "在深入探讨之前，让我们澄清一下，尽管增加了复杂性，但为什么要考虑在DataParallel上使用DistributedDataParallel：\n",
    "\n",
    "如果模型太大而无法容纳在单个GPU上，则必须使用 model parallel 将其拆分到多个GPU中。 DistributedDataParallel与模型并行工作； DataParallel目前不提供。\n",
    "DataParallel是单进程，多线程，并且只能在单台计算机上运行，​​而DistributedDataParallel是多进程，并且可以在单机和分布式训练中使用。因此，即使在单机训练中，您的数据足够小以适合单机，DistributedDataParallel仍要比DataParallel更快。 DistributedDataParallel还可以预先复制模型，而不是在每次迭代时复制模型，并且可以避免PIL全局解释器锁定。\n",
    "如果数据和模型同时很大而无法用一个GPU训练，则可以将model parallel（与DistributedDataParallel结合使用。在这种情况下，每个DistributedDataParallel进程都可以model parallel，并且所有进程共同用数据并行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一段完整的伪代码以及程序启动命令\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from torch.nn import SyncBatchNorm\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "parser = argparse.ArgumentParser(description='training')\n",
    "parser.add_argument('--local_rank', type=str, help='local rank for dist')\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(os.environ['MASTER_ADDR'])\n",
    "print(os.environ['MASTER_PORT'])\n",
    "world_size = torch.cuda.device_count()\n",
    "local_rank = args.local_rank\n",
    "\n",
    "dist.init_process_group(backend='nccl')# 防止timeout\n",
    "\n",
    "torch.cuda.set_device(local_rank) # 为每个gpu分配线程\n",
    "\n",
    "train_dataset = Dataset(...)\n",
    "train_sampler = DistributedSampler(train_dataset)\n",
    "train_loader = Dataloader(dataset=train_dataet, sampler=train_sampler, shuffle=False)\n",
    "\n",
    "val_set = Dataset()\n",
    "val_loader = Dataloader(dataset=val_set)\n",
    "\n",
    "model = MyModel()\n",
    "model = model.cuda() # 先拷到当前进程的GPU中\n",
    "model = SyncBatchNorn.convert_sync_batchnorm(model)\n",
    "model = DistributedDataParallel(model, device_ids=[local_rank], output_devices=local_rank, find_unused_parameters=True)\n",
    "\n",
    "cls_criterion = nn.CrossEntropyLoss()\n",
    "optim = optimizer()\n",
    "scheduler = scheduler()\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    trainer_sampler.set_epoch(epoch)\n",
    "    train()\n",
    "    eval()\n",
    "    # 存储在0进程中的GPU里\n",
    "    if local_rank==0:\n",
    "        log()\n",
    "\n",
    "if local_rank==0:\n",
    "    torch.save(model.module().state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ee6ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行代码\n",
    "CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=8 main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb7f37",
   "metadata": {},
   "source": [
    "因为torch.dist对程序的入口有更改，所以先总结运行代码。torch.dist跟DataParallel不同，需要多进程运行程序，以此达到多机训练的效果。在官方的实现中，使用torch.distributed.launch来启动多进程。除此之外，还使用torch.multiprocessing来手动执行多进程程序。在最新的版本中，官方打算将python -m torch.distributed.lanuch用torchun替代，这里暂时不用。   \n",
    "其中nproc_per_node表示开启的进程数，这里与使用的卡数保持一致。torch.distributed.launch会自动分配一些参数到主程序中，也可以手动修改。这次关注到的有：RANK表示进程的优先级，也可以认为是进程的序列号；MASTER_ADDR和MASTER_PORT分别表示通讯的地址和端口，torch.distributed.launch会将其设置为环境变量；WORLD_SIZE表示gpu*节点数，本例里就是gpu数量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e745e47",
   "metadata": {},
   "source": [
    "需要承接torch.distributed.launch给main.py传递的local_rank参数。local_rank参数表示进程的优先级，也可以认为是进程的序列号"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104dc197",
   "metadata": {},
   "source": [
    "local_rank表示进程的优先级，也可以认为是进程的序列号；MASTER_ADDR和MASTER_PORT分别表示通讯的地址和端口，torch.distributed.launch会将其设置为环境变量；world_size表示gpu*节点数，本例里就是gpu数量。这里代码里print出来展示。\n",
    "dist.init_process_group(backend='nccl')初始化torch.dist的环境。这里backend选择nccl来进行通讯，可以用dist.is_nccl_avaliable()来查看是否可用nccl。除此之外也可以在这里设置一些其他的环境参数。\n",
    "torch.cuda.set_device(local_rank)设置环境CUDA序号"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8186a58",
   "metadata": {},
   "source": [
    "对训练数据集做修改。将dataloader的sampler修改为DistributedSampler，这样保证其每个进程采样的数据是不同的\n",
    "训练集的dataloader的shuffle只能设置为False，DistributedSampler会进行shuffle，如果dataloader再shuffle的话会打乱次序，导致多进程分配的数据不对\n",
    "batch_size设置的是每个进程的，因此不需要像dataparalle一样乘以卡数\n",
    "对验证集可以不做修改，如果每个进程不同的话需要再整合所有进程的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e42e37",
   "metadata": {},
   "source": [
    "跟DataParallel类似的是，加载的模型需要用DDP（DistributedDataParallel）重载一下。这里如果运行时报错有unused_parameters，那么就设置find_unused_parameters=True\n",
    "DDP从原理上应该是多机通讯更新梯度从而保证模型的参数都是一样的，而DataParallel则是在一张卡上集中更新模型权重，再复制到其他卡上\n",
    "对于损失函数、优化器和sheduler都不需要DDP，如果有需要更新的参数的话还是需要DDP重载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b82b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本使用（二）\n",
    "import os\n",
    "import tempfile\n",
    "import torch\n",
    "import torch.distributed as dist #分布\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp #多线程\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "\n",
    "    # Explicitly setting seed to make sure that models created in two processes\n",
    "    # start from same random weights and biases.\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2320ca2",
   "metadata": {},
   "source": [
    "现在，创建一个toy model，将其与DDP封装在一起，并提供一些虚拟输入数据。请注意，如果训练从随机参数开始，则可能要确保所有DDP进程都使用相同的初始值。否则，全局梯度同步将没有意义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f416b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.net1 = nn.Linear(10, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.net2 = nn.Linear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net2(self.relu(self.net1(x)))\n",
    "\n",
    "\n",
    "def demo_basic(rank, world_size):\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    # setup devices for this process, rank 1 uses GPUs [0, 1, 2, 3] and\n",
    "    # rank 2 uses GPUs [4, 5, 6, 7].\n",
    "    n = torch.cuda.device_count() // world_size\n",
    "    device_ids = list(range(rank * n, (rank + 1) * n))\n",
    "\n",
    "    # create model and move it to device_ids[0]\n",
    "    model = ToyModel().to(device_ids[0])\n",
    "    # output_device defaults to device_ids[0]\n",
    "    ddp_model = DDP(model, device_ids=device_ids)\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = ddp_model(torch.randn(20, 10))\n",
    "    labels = torch.randn(20, 5).to(device_ids[0])\n",
    "    loss_fn(outputs, labels).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    cleanup()\n",
    "\n",
    "\n",
    "def run_demo(demo_fn, world_size):\n",
    "    mp.spawn(demo_fn,\n",
    "             args=(world_size,),\n",
    "             nprocs=world_size,\n",
    "             join=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f134393",
   "metadata": {},
   "source": [
    "DDP封装了 lower level distributed communication details，并提供了干净的API，就好像它是本地模型一样。对于基本用例，DDP仅需要几个LoCs来设置 process group。在将DDP应用到更高级的用例时，需要注意一些警告。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe63eb0",
   "metadata": {},
   "source": [
    "处理速度不同步时\n",
    "在DDP中，Model, forward method 和 differentiation of the outputs是分布式的同步点。期望不同的过程以相同的顺序到达同步点，并在大致相同的时间进入每个同步点。否则，快速流程可能会提早到达，并在等待时超时。因此，用户负责进程之间的工作负载分配。有时，由于例如网络延迟，资源争用，不可预测的工作量峰值，不可避免地会出现不同步的处理速度。为了避免在这些情况下超时，请确保在调用init_process_group时传递足够大valuetimeout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377d3dd1",
   "metadata": {},
   "source": [
    "保存和加载 Checkpoints\n",
    "在训练期间，通常使用torch.save 和torch.load 来保存和加载 Checkpoints，有关更多详细信息，请参见 SAVING AND LOADING MODELS，使用DDP时，一种优化方法是仅在一个进程中保存模型，然后将其加载到所有进程中，从而减少写开销，这是正确的，因为所有过程都从相同的参数开始，并且梯度在反向传播中同步，因此优化程序应将参数设置为相同的值。如果使用此优化，请确保在保存完成之前不要启动所有进程。此外，在加载模块时，您需要提供适当的 map_location 参数，以防止进程进入其他人的设备。如果缺少map_location，torch.load 将首先将模块加载到CPU，然后将每个参数复制到保存位置，这将导致同一台机器上的所有进程使用相同的设备集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6c8fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_checkpoint(rank, world_size):\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    # setup devices for this process, rank 1 uses GPUs [0, 1, 2, 3] and\n",
    "    # rank 2 uses GPUs [4, 5, 6, 7].\n",
    "    n = torch.cuda.device_count() // world_size\n",
    "    device_ids = list(range(rank * n, (rank + 1) * n))\n",
    "\n",
    "    model = ToyModel().to(device_ids[0])\n",
    "    # output_device defaults to device_ids[0]\n",
    "    ddp_model = DDP(model, device_ids=device_ids)\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
    "\n",
    "    CHECKPOINT_PATH = tempfile.gettempdir() + \"/model.checkpoint\"\n",
    "    if rank == 0:\n",
    "        # All processes should see same parameters as they all start from same\n",
    "        # random parameters and gradients are synchronized in backward passes.\n",
    "        # Therefore, saving it in one process is sufficient.\n",
    "        torch.save(ddp_model.state_dict(), CHECKPOINT_PATH)\n",
    "\n",
    "    # Use a barrier() to make sure that process 1 loads the model after process\n",
    "    # 0 saves it.\n",
    "    dist.barrier()\n",
    "    # configure map_location properly\n",
    "    rank0_devices = [x - rank * len(device_ids) for x in device_ids]\n",
    "    device_pairs = zip(rank0_devices, device_ids)\n",
    "    map_location = {'cuda:%d' % x: 'cuda:%d' % y for x, y in device_pairs}\n",
    "    ddp_model.load_state_dict(\n",
    "        torch.load(CHECKPOINT_PATH, map_location=map_location))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = ddp_model(torch.randn(20, 10))\n",
    "    labels = torch.randn(20, 5).to(device_ids[0])\n",
    "    loss_fn = nn.MSELoss()\n",
    "    loss_fn(outputs, labels).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Use a barrier() to make sure that all processes have finished reading the\n",
    "    # checkpoint\n",
    "    dist.barrier()\n",
    "\n",
    "    if rank == 0:\n",
    "        os.remove(CHECKPOINT_PATH)\n",
    "\n",
    "    cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea053eda",
   "metadata": {},
   "source": [
    "**DDP 和 Model Parallelism 一起使用(防止出错，非必要不用)**    \n",
    "DDP还可以与 Model Parallelism一起使用，但是不支持进程内的复制。您需要为每个module 副本创建一个进程，与每个进程的多个副本相比，通常可以提高性能。 这种训练方式在具有巨大的数据量较大的模型时特别有用。使用此功能时，需要小心地实现 multi-GPU model，以避免使用硬编码的设备，因为会将不同的模型副本放置到不同的设备上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lass ToyMpModel(nn.Module):\n",
    "    def __init__(self, dev0, dev1):\n",
    "        super(ToyMpModel, self).__init__()\n",
    "        self.dev0 = dev0\n",
    "        self.dev1 = dev1\n",
    "        self.net1 = torch.nn.Linear(10, 10).to(dev0)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.net2 = torch.nn.Linear(10, 5).to(dev1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.dev0)\n",
    "        x = self.relu(self.net1(x))\n",
    "        x = x.to(self.dev1)\n",
    "        return self.net2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4234104",
   "metadata": {},
   "source": [
    "将multi-GPU model 传递给DDP时，不得设置device_ids和output_device，输入和输出数据将通过应用程序或模型forward() 方法放置在适当的设备中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ab6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_model_parallel(rank, world_size):\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    # setup mp_model and devices for this process\n",
    "    dev0 = rank * 2\n",
    "    dev1 = rank * 2 + 1\n",
    "    mp_model = ToyMpModel(dev0, dev1)\n",
    "    ddp_mp_model = DDP(mp_model)\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(ddp_mp_model.parameters(), lr=0.001)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    # outputs will be on dev1\n",
    "    outputs = ddp_mp_model(torch.randn(20, 10))\n",
    "    labels = torch.randn(20, 5).to(dev1)\n",
    "    loss_fn(outputs, labels).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    cleanup()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_demo(demo_basic, 2)\n",
    "    run_demo(demo_checkpoint, 2)\n",
    "\n",
    "    if torch.cuda.device_count() >= 8:\n",
    "        run_demo(demo_model_parallel, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8094c5",
   "metadata": {},
   "source": [
    "[当代研究生应当掌握的5种Pytorch并行训练方法（单机多卡）](https://mp.weixin.qq.com/s/YwvO_5y67ZxYiR_-BlrNOg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c441da4c",
   "metadata": {},
   "source": [
    "[**官网**](https://pytorch.org/docs/1.10/generated/torch.nn.parallel.DistributedDataParallel.html?highlight=distributeddataparallel#torch.nn.parallel.DistributedDataParallel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
